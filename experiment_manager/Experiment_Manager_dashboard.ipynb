{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard\n",
    "\n",
    "In this Notebook, we interact with the Experiment Manager to configure, setup and run experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies, initialise configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Imports and such\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "%config Completer.use_jedi = False # to avoid autocomplete errors in Jupyter server\n",
    "from ipywidgets import GridspecLayout, GridBox, Layout, Output\n",
    "import dashboard_ui\n",
    "\n",
    "dashboard_ui = dashboard_ui.DashboardUI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Model, Dataset and Fusion Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide Data Handler\n",
    "- Only if you wish to use a Custom Dataset\n",
    "- Choose Yes in the `Custom Dataset?` option below\n",
    "\n",
    "Populate and then run the cell below to save the provided Data Handler class to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile custom_data_handler.py\n",
    "### YOUR DATAHANDLER code goes below\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ibmfl.data.data_handler import DataHandler\n",
    "from ibmfl.util.datasets import load_mnist\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MnistKerasDataHandler(DataHandler):\n",
    "    \"\"\"\n",
    "    Data handler for MNIST dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_config=None, channels_first=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.file_name = None\n",
    "        if data_config is not None:\n",
    "            # Ensure your data files are either npz or csv\n",
    "            if 'npz_file' in data_config:\n",
    "                self.file_name = data_config['npz_file']\n",
    "            elif 'txt_file' in data_config:\n",
    "                self.file_name = data_config['txt_file']\n",
    "        self.channels_first = channels_first\n",
    "\n",
    "        # load the datasets\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = self.load_dataset()\n",
    "\n",
    "        # pre-process the datasets\n",
    "        self.preprocess()\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        Gets pre-process mnist training and testing data.\n",
    "\n",
    "        :return: the training and testing data.\n",
    "        :rtype: `tuple`\n",
    "        \"\"\"\n",
    "        return (self.x_train, self.y_train), (self.x_test, self.y_test)\n",
    "\n",
    "    def load_dataset(self, nb_points=500):\n",
    "        \"\"\"\n",
    "        Loads the training and testing datasets from a given local path. \\\n",
    "        If no local path is provided, it will download the original MNIST \\\n",
    "        dataset online, and reduce the dataset size to contain \\\n",
    "        500 data points per training and testing dataset. \\\n",
    "        Because this method \\\n",
    "        is for testing it takes as input the number of datapoints, nb_points, \\\n",
    "        to be included in the training and testing set.\n",
    "\n",
    "        :param nb_points: Number of data points to be included in each set if\n",
    "        no local dataset is provided.\n",
    "        :type nb_points: `int`\n",
    "        :return: training and testing datasets\n",
    "        :rtype: `tuple`\n",
    "        \"\"\"\n",
    "        if self.file_name is None:\n",
    "            (x_train, y_train), (x_test, y_test) = load_mnist()\n",
    "            # Reduce datapoints to make test faster\n",
    "            x_train = x_train[:nb_points]\n",
    "            y_train = y_train[:nb_points]\n",
    "            x_test = x_test[:nb_points]\n",
    "            y_test = y_test[:nb_points]\n",
    "        else:\n",
    "            try:\n",
    "                logger.info('Loaded training data from ' + str(self.file_name))\n",
    "                data_train = np.load(self.file_name)\n",
    "                x_train = data_train['x_train']\n",
    "                y_train = data_train['y_train']\n",
    "                x_test = data_train['x_test']\n",
    "                y_test = data_train['y_test']\n",
    "            except Exception:\n",
    "                raise IOError('Unable to load training data from path '\n",
    "                              'provided in config file: ' +\n",
    "                              self.file_name)\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Preprocesses the training and testing dataset, \\\n",
    "        e.g., reshape the images according to self.channels_first; \\\n",
    "        convert the labels to binary class matrices.\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        num_classes = 10\n",
    "        img_rows, img_cols = 28, 28\n",
    "\n",
    "        if self.channels_first:\n",
    "            self.x_train = self.x_train.reshape(self.x_train.shape[0], 1, img_rows, img_cols)\n",
    "            self.x_test = self.x_test.reshape(self.x_test.shape[0], 1, img_rows, img_cols)\n",
    "        else:\n",
    "            self.x_train = self.x_train.reshape(self.x_train.shape[0], img_rows, img_cols, 1)\n",
    "            self.x_test = self.x_test.reshape(self.x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        self.y_train = np.eye(num_classes)[self.y_train]\n",
    "        self.y_test = np.eye(num_classes)[self.y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Model, Dataset and Fusion Algorithm\n",
    "\n",
    "components = dashboard_ui.generate_model_dataset_fusion_ui()\n",
    "\n",
    "# GridBox layout for UI\n",
    "grid = GridspecLayout(2,2)\n",
    "\n",
    "grid[0,:] = GridBox(children=list(components[:-4]),\n",
    "                    layout=Layout(\n",
    "                        width='100%',\n",
    "                        grid_template_rows='auto auto',\n",
    "                        grid_template_columns='48% 48%',\n",
    "                        grid_template_areas='''\n",
    "                        \"model_header model_header\"\n",
    "                        \"model_dr model_upload\"\n",
    "                        \"dataset_header dataset_header\"\n",
    "                        \"dataset dataset_spl\"\n",
    "                        \"ppp ppp\"\n",
    "                        '''\n",
    "#                         ,border='0.5px solid black'\n",
    "                    ))\n",
    "\n",
    "grid[1,:] = GridBox(children=list(components[-4:]),\n",
    "                    layout=Layout(\n",
    "                        height='150px',\n",
    "                        width='100%',\n",
    "                        grid_template_rows='auto auto',\n",
    "                        grid_template_columns='48% 48%',\n",
    "                        grid_gap = '0px 0px',\n",
    "                        grid_template_areas='''\n",
    "                        \"custom_data  custom_data_html\"\n",
    "                        \"fusion_dr metrics_choice\"\n",
    "                        '''\n",
    "#                         , border='0.5px solid black'\n",
    "                    ))\n",
    "# grid[2,:] = GridBox(children=list(components[-1:]),\n",
    "#                     layout=Layout(\n",
    "#                         height='55px',\n",
    "#                         width='auto',\n",
    "#                         grid_template_rows='100%',\n",
    "#                         grid_template_columns='100%',\n",
    "#                         grid_template_areas='''\n",
    "#                         \"fusion_dr\"\n",
    "#                         ''',\n",
    "#                         border='0.5px solid black'\n",
    "#                     ))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose number of parties and hyperparameters\n",
    "Ensure you click `Confirm Hyperparameters` when done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Parties and Hyperparameters\n",
    "\n",
    "components = list(dashboard_ui.generate_parties_hyperparams_ui())\n",
    "\n",
    "# GridBox layout for UI\n",
    "grid = GridspecLayout(2,3)\n",
    "\n",
    "grid[0,:] = GridBox(children=components[:-2],\n",
    "       layout = Layout(\n",
    "           width='100%',\n",
    "           grid_template_rows='auto auto',\n",
    "           grid_template_columns='48% 48%',\n",
    "           grid_template_areas='''\n",
    "           \"header_parties header_parties\"\n",
    "           \"parties parties\"\n",
    "           \"header_hyperparams header_hyperparams\"\n",
    "            ''')\n",
    "       )\n",
    "# Nested grid to vary spacing across various widgets\n",
    "sub_grid_hyperparams = GridspecLayout(2,3)\n",
    "sub_grid_hyperparams[0,:] = components[-1]\n",
    "sub_grid_hyperparams[1,1] = components[-2]\n",
    "\n",
    "grid[1, :] = sub_grid_hyperparams\n",
    "\n",
    "party_hyperparam_ui = Output()\n",
    "\n",
    "with party_hyperparam_ui:\n",
    "    display(grid)\n",
    "party_hyperparam_ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide Party specific data files\n",
    "\n",
    "- Only if you wish to use a Custom Dataset\n",
    "- Chose Yes in the `Custom Dataset?` option in Step 1.2 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Upload party data files for each party:\n",
    "if 'custom_data' in dashboard_ui.mgr.nb_config:\n",
    "    upload_boxes = dashboard_ui.generate_custom_party_data_ui()\n",
    "    for each in upload_boxes:\n",
    "        display(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose whether to run locally or on remote machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Local or Remote run\n",
    "\n",
    "components = dashboard_ui.generate_local_remote_ui()\n",
    "# grid for displaying networking fields -- IP addr, port, ssh user, paths\n",
    "partyDetails_grid = GridspecLayout(1,3)\n",
    "partyDetails_grid[0, :] = components[1] # networking_deets_box \n",
    "\n",
    "display(components[0])\n",
    "partyDetails_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and View Aggregator and Party Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Generate Configs and Display them\n",
    "\n",
    "components = dashboard_ui.generate_display_configs_ui()\n",
    "\n",
    "# grid for displaying generated configurations\n",
    "display_grid_1 = GridspecLayout(1,3)\n",
    "display_grid_1[0, :] = components[1] # config_box\n",
    "\n",
    "display_grid_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Experiment and Visualise Metrics\n",
    "If the configs above look alright, go ahead and run the cell below to run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Run the experiment and see charts\n",
    "\n",
    "import ibmfl_cli_automator.run as ibmfl_runner\n",
    "from ipywidgets import Button, VBox, Output\n",
    "\n",
    "exp_runner = ibmfl_runner.Runner()\n",
    "\n",
    "monitoring_box = VBox()\n",
    "\n",
    "no_plots_for_these = ['Federated Averaging', 'Gradient Averaging', 'Probabilistic Federated Neural Matching', 'Zeno', 'Shuffled Iterative Avg']\n",
    "\n",
    "plot_button = Button(\n",
    "        description='Show Charts',\n",
    "        disabled=False,\n",
    "        button_style='warning', # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip='Displays the various plots for the experiment that ran',\n",
    "        layout = Layout(width='120px', height='40px', margin='5px 50px 5px 400px') ## margin to position button centrally\n",
    "    )\n",
    "\n",
    "\n",
    "def invoke_runner():\n",
    "    monitoring_out = Output(layout={'border': '0.5px solid black'})\n",
    "    monitoring_box.children = [monitoring_out]\n",
    "    display(display_grid_2)\n",
    "\n",
    "    # some values needed by the Runner; there's only one trial for now\n",
    "    dashboard_ui.mgr.run_details['experiments'][0]['shuffle_party_machines'] = False\n",
    "    dashboard_ui.mgr.run_details['experiments'][0]['n_trials'] = 1\n",
    "    dashboard_ui.mgr.run_details['experiments'][0]['n_parties'] = dashboard_ui.mgr.nb_config['global']['num_parties']\n",
    "    dashboard_ui.mgr.run_details['experiments'][0]['n_rounds'] = dashboard_ui.mgr.nb_config['global']['rounds']\n",
    "\n",
    "    # values for postprocessing and showing default metrics\n",
    "    if dashboard_ui.mgr.nb_config['record_metrics']:\n",
    "        dashboard_ui.mgr.run_details['experiments'][0]['postproc_fn'] = {}\n",
    "        dashboard_ui.mgr.run_details['experiments'][0]['postproc_fn'] = 'gen_reward_vs_time_plots'\n",
    "        dashboard_ui.mgr.run_details['experiments'][0]['postproc_x_key'] = 'post_train:ts'\n",
    "        dashboard_ui.mgr.run_details['experiments'][0]['postproc_y_keys'] = ['post_train:eval:loss', 'post_train:eval:acc']#, 'post_train:eval:precision weighted', 'post_train:eval:recall weighted']\n",
    "\n",
    "    exp_machines = exp_runner.convert_machine_dict_from_nb_to_cli(dashboard_ui.mgr.run_details['machines'])\n",
    "\n",
    "    for exp_info in dashboard_ui.mgr.run_details['experiments']:\n",
    "        with open('{}/config_agg.yml'.format(dashboard_ui.mgr.nb_config['local_conf_dir']), 'r') as config_agg_file:\n",
    "            config_agg = config_agg_file.read()\n",
    "        config_parties = []\n",
    "        for pi in range(exp_info['n_parties']):\n",
    "            with open('{}/config_party{}.yml'.format(dashboard_ui.mgr.nb_config['local_conf_dir'], pi), 'r') as config_party_file:\n",
    "                config_parties += [config_party_file.read()]\n",
    "        with monitoring_out:\n",
    "            display(exp_runner.run_experiment(exp_info, dashboard_ui.mgr.run_details['machines'],\n",
    "                                              config_agg, config_parties, ui_mode='nb', ts=dashboard_ui.mgr.nb_config['timestamp_str']) \\\n",
    "                    or 'Finished!')\n",
    "\n",
    "    if dashboard_ui.mgr.nb_config['record_metrics']:\n",
    "        if 'Keras' in dashboard_ui.mgr.nb_config['model'] and dashboard_ui.mgr.nb_config['fusion'] not in no_plots_for_these:\n",
    "            # only some Keras models have plots currently\n",
    "            monitoring_box.children = monitoring_box.children + (plot_button,)\n",
    "        else:\n",
    "            with monitoring_out:\n",
    "                display('Plots for chosen model/fusion algorithm are not supported yet') # metrics processing not in place\n",
    "    else:\n",
    "        with monitoring_out:\n",
    "            display('No metrics were recorded, so no plots to show')\n",
    "\n",
    "plots_box = VBox()\n",
    "\n",
    "def get_plots(b):\n",
    "    b.disabled = True\n",
    "    plots_out = Output(layout={'border': '0.5px solid black'})\n",
    "    plots_box.children = [plots_out]\n",
    "    display(display_grid_3)\n",
    "    # generate the plot(s)\n",
    "    with plots_out:\n",
    "        display(exp_info = exp_runner.call_postproc_fn())\n",
    "\n",
    "plot_button.on_click(get_plots)\n",
    "\n",
    "# grid for displaying progress of running experiment\n",
    "display_grid_2 = GridspecLayout(1,1)\n",
    "display_grid_2[0, :] = monitoring_box\n",
    "\n",
    "# grid for displaying charts from collected metrics\n",
    "display_grid_3 = GridspecLayout(1,1)\n",
    "display_grid_3[0, :] = plots_box\n",
    "\n",
    "invoke_runner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibmfl-venv",
   "language": "python",
   "name": "ibmfl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
